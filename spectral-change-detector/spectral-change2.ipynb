{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "import geemap\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import geemap.colormaps as cm\n",
    "\n",
    "import seaborn as sns\n",
    "import geopandas as gpd\n",
    "\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    ee.Initialize()\n",
    "except: \n",
    "    ee.Authenticate()\n",
    "    ee.Initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mask clouds using the Sentinel-2 QA band\n",
    "def maskS2clouds(image):\n",
    "    qa = image.select('QA60')\n",
    "\n",
    "    # Bits 10 and 11 are clouds and cirrus, respectively.\n",
    "    cloudBitMask = 1 << 10\n",
    "    cirrusBitMask = 1 << 11\n",
    "\n",
    "    # Both flags should be set to zero, indicating clear conditions.\n",
    "    mask = qa.bitwiseAnd(cloudBitMask).eq(0) \\\n",
    "        .And(qa.bitwiseAnd(cirrusBitMask).eq(0))\n",
    "\n",
    "    return image.updateMask(mask) \\\n",
    "        .divide(10000) \\\n",
    "        .copyProperties(image, ['system:time_start']) \n",
    "\n",
    "# Mask out water\n",
    "def maskWater(image):\n",
    "    return image.updateMask(waterMask.select('water_mask').lt(1))\n",
    "\n",
    "# Function to filter images by NDSI_Snow_Cover value < 5\n",
    "def maskS2snow(image):\n",
    "\n",
    "    mask = image.select('MSK_SNWPRB').lt(0.009) \\\n",
    "    \n",
    "    return image.updateMask(mask) \\\n",
    "            .copyProperties(image, ['system:time_start'])\n",
    "\n",
    "# Mask white to remove cloudy or snowy pixels\n",
    "def maskWhite(image):\n",
    "    grayscale = image.expression(\n",
    "            '(.3 * 1e4 * R) + (.59 * 1e4 * G) + (.11 * 1e4 * B)', {\n",
    "            # '(R + G + B) / 3', {\n",
    "            'R': image.select('B4'),\n",
    "            'G': image.select('B3'),\n",
    "            'B': image.select('B2')\n",
    "        })\n",
    "    \n",
    "    white_mask = grayscale.lte(2000)\n",
    "\n",
    "    return image.updateMask(white_mask).copyProperties(image,['system:time_start'])\n",
    "\n",
    "def clp(image):\n",
    "    return image.clip(aoi)\n",
    "\n",
    "# Make an NDVI band\n",
    "def addNDVI(image):\n",
    "    ndvi = image.normalizedDifference(['B8', 'B4']).rename('NDVI')\n",
    "    return image.addBands(ndvi).copyProperties(image, ['system:time_start'])\n",
    "\n",
    "# Get yearly statistics for the chosen index\n",
    "def annual_images(y):\n",
    "    range_year = ee.Filter.calendarRange(y, y, 'year')\n",
    "    range_month = ee.Filter.calendarRange(start_month, end_month, 'month')\n",
    "    filtered_dataset = (index_collection\n",
    "                        .filter(range_year)\n",
    "                        .filter(range_month)\n",
    "                        .map(lambda image: image.addBands(image.metadata('system:time_start').divide(3.154e10)))) # Needed for linear regression \n",
    "    \n",
    "    # Print out the number of images in the ImageCollection for each year\n",
    "    num_images = filtered_dataset.size()\n",
    "    \n",
    "    \n",
    "    # Choose the reducer based on the analysis choice\n",
    "    if analysis == 'mean':\n",
    "        reducer = ee.Reducer.mean().combine(\n",
    "            reducer2=ee.Reducer.stdDev(),\n",
    "            sharedInputs=True\n",
    "        )\n",
    "    elif analysis == 'min' or analysis == 'max':\n",
    "        reducer = ee.Reducer.mean().combine(\n",
    "            reducer2=ee.Reducer.minMax(),\n",
    "            sharedInputs=True\n",
    "        )\n",
    "    elif analysis == 'median':\n",
    "        reducer = ee.Reducer.mean().combine(\n",
    "            reducer2=ee.Reducer.median(),\n",
    "            sharedInputs=True\n",
    "        )\n",
    "\n",
    "    # Use the combined reducer to get the statistics\n",
    "    stats = filtered_dataset.reduce(reducer)\n",
    "    return stats.set('year', y).set('num', num_images)\n",
    "\n",
    "# get the seasonal (one year) trend\n",
    "def intrayear(index_collection):\n",
    "    range_year = ee.Filter.calendarRange(start_year, end_year, 'year')\n",
    "    range_month = ee.Filter.calendarRange(start_month, end_month, 'month')\n",
    "    filtered_dataset = (index_collection\n",
    "                        .filter(range_year)\n",
    "                        .filter(range_month)\n",
    "                        .map(lambda image: image.addBands(image.metadata('system:time_start').divide(3.154e10)))) # Needed for linear regression \n",
    "    \n",
    "    num_images = filtered_dataset.size()\n",
    "\n",
    "    # return filtered_dataset\n",
    "    return filtered_dataset.set('year', start_year).set('num', num_images)\n",
    "\n",
    "# function to get the trend of the trend\n",
    "def annual_trend(y):\n",
    "    range_year = ee.Filter.calendarRange(y, y, 'year')\n",
    "    range_month = ee.Filter.calendarRange(start_month, end_month, 'month')\n",
    "    filtered_dataset = (index_collection\n",
    "                        .filter(range_year)\n",
    "                        .filter(range_month)\n",
    "                        .map(lambda image: image.addBands(image.metadata('system:time_start').divide(3.154e10)))) # Needed for linear regression \n",
    "    \n",
    "    # Print out the number of images in the ImageCollection for each year\n",
    "    num_images = filtered_dataset.size()\n",
    "    \n",
    "    # Use the combined reducer to get the statistics\n",
    "    stats = filtered_dataset.reduce(reducer = ee.Reducer.linearFit())\n",
    "    return stats.set('year', y).set('num', num_images)\n",
    "\n",
    "def createTimeBand(image):   \n",
    "    return image.addBands(image.metadata('system:time_start').divide(3.154e10))\n",
    "\n",
    "# get the mean NDVI for a region\n",
    "def meanNDVI(image): \n",
    "    ndvi = image.select('NDVI')\n",
    "    ndvi_mean = ndvi.reduceRegion(\n",
    "        reducer=ee.Reducer.mean(),\n",
    "        geometry=aoi,\n",
    "        scale=10\n",
    "    ).get('NDVI')\n",
    "\n",
    "    ndvi_mean = ee.Number(ndvi_mean)\n",
    "    \n",
    "    return image.set('ndvi_mean', ndvi_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build collection\n",
    "\n",
    "Define AOI and build image collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HYBAS_ID = 8100362560\n",
    "\n",
    "aoi = ee.FeatureCollection(\"WWF/HydroSHEDS/v1/Basins/hybas_10\").filter(ee.Filter.eq('HYBAS_ID', HYBAS_ID))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get water mask\n",
    "waterMask = (\n",
    "    ee.ImageCollection('MODIS/006/MOD44W') \n",
    "    .filter(ee.Filter.date('2015-01-01', '2015-01-02')) \n",
    "    .select('water_mask') \\\n",
    "    .first()\n",
    ")\n",
    "# Get Sentinel 2 harmonized images\n",
    "dataset = (\n",
    "    ee.ImageCollection(\"COPERNICUS/S2_SR_HARMONIZED\")\n",
    "                #  Filter by year\n",
    "                  .filter(ee.Filter.calendarRange(2019,2023,'year'))\n",
    "                #  Filter by month\n",
    "                  .filter(ee.Filter.calendarRange(6,9,'month'))\n",
    "                #  Pre-filter to get less cloudy granules.\n",
    "                  .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 5))\n",
    "                  .filterBounds(aoi)\n",
    "                #   // This one's Toolik\n",
    "                # .filterBounds(ee.Geometry.Point(-149.5427, 68.6267).buffer(500))\n",
    "                #   // This one's Russian tree tracks\n",
    "                # .filterBounds(ee.Geometry.Point(133.16008, 66.82386).buffer(1000))\n",
    "                  .map(clp)\n",
    "                  .map(maskS2clouds)\n",
    "                  .map(maskS2snow)\n",
    "                  .map(maskWhite)\n",
    "                  .map(maskWater)\n",
    "                  .map(addNDVI)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long = aoi.geometry().centroid().coordinates().get(0).getInfo()\n",
    "lat = aoi.geometry().centroid().coordinates().get(1).getInfo()\n",
    "\n",
    "Map = geemap.Map(center = (lat, long), zoom = 11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do analysis\n",
    "select your index and time frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick your index\n",
    "index = 'NDVI'\n",
    "# Choose 'mean', 'median', 'min', or 'max' for analysis\n",
    "analysis = 'max'  \n",
    "\n",
    "# limit beyond your ImageCollection\n",
    "start_year = 2019\n",
    "end_year = 2023\n",
    "start_month = 6\n",
    "end_month = 8\n",
    "\n",
    "# image collection with index band\n",
    "index_collection = dataset.select(index)  \n",
    "\n",
    "# Generate list of years\n",
    "years = ee.List.sequence(start_year, end_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Skip to different sections to:\n",
    "- view spectral trends on the map <br>\n",
    "- plot the index values of different regions <br>\n",
    "- perform a KMeans cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View Trend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temporal trend: change in index over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if start_year == end_year:\n",
    "    intrayear_collection = intrayear(index_collection)\n",
    "\n",
    "    item = intrayear_collection.getInfo()\n",
    "    print(\"Year:\", item['properties']['year'], \"Number of images:\", item['properties']['num'])\n",
    "\n",
    "    # Get linear fit to pixelwise trend of annual max NDVI\n",
    "    trend = intrayear_collection.select(['system:time_start',\n",
    "                                index\n",
    "                                ]).reduce(ee.Reducer.linearFit())\n",
    "\n",
    "else:\n",
    "\n",
    "    # Map over years to get yearly statistics\n",
    "    yearwise_ndvi = years.map(annual_images)\n",
    "\n",
    "    for item in yearwise_ndvi.getInfo():\n",
    "        print(\"Year:\", item['properties']['year'], \"Number of images:\", item['properties']['num'])\n",
    "\n",
    "        yearCompCol = ee.ImageCollection.fromImages(yearwise_ndvi)\n",
    "\n",
    "        # Get linear fit to pixelwise trend of annual max NDVI\n",
    "        trend = yearCompCol.select(['system:time_start_mean',\n",
    "                                    f'{index}_{analysis}'\n",
    "                                    ]).reduce(ee.Reducer.linearFit())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trend of the trend: change in seasonal trend over time (skip the above cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map over years to get annual trend\n",
    "yearwise_trend = years.map(annual_trend)\n",
    "\n",
    "for item in yearwise_trend.getInfo():\n",
    "    print(\"Year:\", item['properties']['year'], \"Number of images:\", item['properties']['num'])\n",
    "\n",
    "yearCompCol = ee.ImageCollection.fromImages(yearwise_trend)\n",
    "\n",
    "trend = yearCompCol.reduce(ee.Reducer.linearFit())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To determine the min and max values of the trend, sample and plot the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slope = trend.select('scale')\n",
    "samples = slope.sample(region=aoi, scale=10, numPixels=500, geometries=True).getInfo()\n",
    "\n",
    "slope_values = [feature['properties']['scale'] for feature in samples['features']]\n",
    "coordinates = [feature['geometry']['coordinates'] for feature in samples['features']]\n",
    "\n",
    "coords = np.array(coordinates)\n",
    "lons = coords[:, 0]\n",
    "lats = coords[:, 1]\n",
    "\n",
    "# Plot the slope values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(lons, lats, c=slope_values, cmap='viridis', marker='o')\n",
    "plt.colorbar(label='Slope')\n",
    "plt.title('Slope Values Over Region')\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set trend min and max values\n",
    "tMin = -0.125\n",
    "tMax = 0.05\n",
    "\n",
    "image_limit = 5\n",
    "\n",
    "# view RGB\n",
    "for image_id in intrayear(dataset).aggregate_array(\"system:index\").getInfo()[0:image_limit]:\n",
    "        image = intrayear(dataset).filterMetadata(\"system:index\", \"equals\", image_id).first()\n",
    "        \n",
    "        image_RGB = image.select('B4', 'B3', 'B2') \n",
    "        RGB_vis_params = {'min': 0.0, 'max': 0.3}\n",
    "        Map.addLayer(image_RGB, RGB_vis_params, ee.Image(image).date().format('yyyy-MM-dd').getInfo(), True)\n",
    "\n",
    "# view NDVI\n",
    "# for image_id in intrayear_collection.aggregate_array(\"system:index\").getInfo()[0:image_limit]:\n",
    "#         image = intrayear_collection.filterMetadata(\"system:index\", \"equals\", image_id).first()\n",
    "#         date_string = ee.Image(image).date().format('yyyy-MM-dd').getInfo()\n",
    "\n",
    "#         Map.addLayer(image.select('NDVI'), {}, f'{date_string}_NDVI', False)\n",
    "\n",
    "# view trend\n",
    "Map.addLayer(trend.select('scale'),\n",
    "              {'min': tMin, 'max': tMax,\n",
    "            'palette': ['red', 'white', 'blue']\n",
    "            },\n",
    " 'trend')\n",
    "\n",
    "# add colorbar for trend\n",
    "Map.add_colorbar_branca(colors=['red', 'white', 'blue'], vmin=tMin, vmax=tMax, layer_name='trend')\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare trends within drawn polygons\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell and draw a region of interest on the map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick the image with the most coverage\n",
    "image_RGB = dataset.sort('NODATA_PIXEL_PERCENTAGE', False).first().select('B4', 'B3', 'B2')\n",
    "\n",
    "RGB_vis_params = {'min': 0.0, 'max': 0.3}\n",
    "Map.addLayer(image_RGB, RGB_vis_params, ee.Image(image_RGB).date().format('yyyy-MM-dd').getInfo(), True)\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate mean NDVI of the area for each date and convert to a data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clip to polygon\n",
    "aoi = ee.FeatureCollection(Map.draw_features)\n",
    "index_collection = index_collection.map(clp)\n",
    "\n",
    "# average NDVI\n",
    "ndvi_collection = index_collection.map(meanNDVI)\n",
    "\n",
    "# Map.addLayer(index_collection.first(), {}, \"clip\")\n",
    "# Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list = ndvi_collection.getInfo()\n",
    "data = []\n",
    "\n",
    "# add date and mean NDVI to data frame\n",
    "for img in image_list['features']:\n",
    "    properties = img['properties']\n",
    "    data.append({\n",
    "            'date': ee.Date(properties['system:time_start']).format('YYYY-MM-dd').getInfo(),\n",
    "            'ndvi_mean': properties.get('ndvi_mean')\n",
    "        })\n",
    "    \n",
    "df = pd.DataFrame(data, columns=['date', 'ndvi_mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save csv \n",
    "df.to_csv('/sciclone/home/aekastning/pycogss_recipes/spectral-change-detector/output/8100362560_wt.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have drawn your AOIs and saved their NDVI values, you can load two CSVs to compare their data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load NDVI values for water track\n",
    "wt = pd.read_csv('/sciclone/home/aekastning/pycogss_recipes/spectral-change-detector/output/8100362730_wt.csv')\n",
    "\n",
    "# load NDVI values for intertrack region\n",
    "intertrack = pd.read_csv('/sciclone/home/aekastning/pycogss_recipes/spectral-change-detector/output/8100362730_slp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert date to datetime\n",
    "wt['date'] = pd.to_datetime(wt['date'])\n",
    "intertrack['date'] = pd.to_datetime(intertrack['date'])\n",
    "\n",
    "# add ordinal date column to assist with plotting\n",
    "wt['date_ordinal'] = wt['date'].apply(lambda x: x.toordinal())\n",
    "intertrack['date_ordinal'] = intertrack['date'].apply(lambda x: x.toordinal())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wt['region'] = 'track'\n",
    "intertrack['region'] = 'intertrack'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear regression\n",
    "sns.set_theme(style = 'white')\n",
    "sns.lmplot(x='date_ordinal', y='ndvi_mean', data=intertrack)\n",
    "\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Mean NDVI')\n",
    "plt.title('Temporal change in NDVI of inter-track region')\n",
    "\n",
    "interval = 21\n",
    "tick_positions = intertrack['date_ordinal'][::interval]\n",
    "tick_labels = intertrack['date'][::interval].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "plt.xticks(ticks=tick_positions, labels=tick_labels,)\n",
    "\n",
    "plt.gca().xaxis.grid(False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot inverse vs normal greening\n",
    "run above cells to extract NDVI values for water track and intertrack regions.\n",
    "then, save data as either inverse or normal greening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverse = pd.concat([wt, intertrack], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal = pd.concat([wt, intertrack], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "linear regression of NDVI over time for EITHER inverse or normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style = 'white')\n",
    "fig_inv = sns.lmplot(x='date_ordinal', y='ndvi_mean', data=inverse, hue = 'region')\n",
    "\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Mean NDVI')\n",
    "plt.title('Temporal NDVI Trends of Inverse Greening Water Tracks and Surrounding Hillslope')\n",
    "\n",
    "interval = 85\n",
    "tick_positions = inverse['date_ordinal'][::interval]\n",
    "tick_labels = inverse['date'][::interval].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "plt.xticks(ticks=tick_positions, labels=tick_labels,)\n",
    "\n",
    "plt.gca().xaxis.grid(False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save figure (can't do lmplot with subplot axes)\n",
    "fig_inv.savefig('/sciclone/home/aekastning/pycogss_recipes/spectral-change-detector/output/inv.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "repeat the above steps for other region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter dfs to for June ndvi\n",
    "normalJune = normal[normal['date'].dt.month == 6]\n",
    "inverseJune = inverse[inverse['date'].dt.month == 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# big fig\n",
    "\n",
    "sns.set_theme(style='white')\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
    "\n",
    "# Normal Greening linear regression\n",
    "normal_img = plt.imread('/sciclone/home/aekastning/pycogss_recipes/spectral-change-detector/output/normal.png')\n",
    "axes[0, 0].imshow(normal_img)\n",
    "axes[0, 0].axis('off') \n",
    "\n",
    "# inverse greening linear regression\n",
    "inverse_img = plt.imread('/sciclone/home/aekastning/pycogss_recipes/spectral-change-detector/output/inv.png')\n",
    "axes[0, 1].imshow(inverse_img)\n",
    "axes[0, 1].axis('off')\n",
    "\n",
    "# June Greeness\n",
    "sns.boxplot(x='region', y='ndvi_mean', data=normalJune, ax=axes[1, 0])\n",
    "axes[1, 0].set_xlabel('Region')\n",
    "axes[1, 0].set_ylabel('June NDVI')\n",
    "axes[1, 0].set_title('June Greenness by Region')\n",
    "\n",
    "sns.boxplot(x='region', y='ndvi_mean', data=inverseJune, ax=axes[1, 1])\n",
    "axes[1, 1].set_xlabel('Region')\n",
    "axes[1, 1].set_ylabel('June NDVI')\n",
    "axes[1, 1].set_title('June Greenness by Region with Inverse Greening')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Means Clustering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make an image with June Greeness, Greening Season Trend, Interannual greening trend, and Trend of Trend as bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick the image with the most coverage\n",
    "\n",
    "trend_image = dataset.sort('NODATA_PIXEL_PERCENTAGE', False).first().select('B4', 'B3', 'B2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trend of trend\n",
    "yearwise_trend = years.map(annual_trend)\n",
    "\n",
    "for item in yearwise_trend.getInfo():\n",
    "    print(\"Year:\", item['properties']['year'], \"Number of images:\", item['properties']['num'])\n",
    "\n",
    "yearCompCol = ee.ImageCollection.fromImages(yearwise_trend)\n",
    "\n",
    "trend = yearCompCol.reduce(ee.Reducer.linearFit())\n",
    "\n",
    "scale = trend.select('scale')\n",
    "\n",
    "trend_image = trend_image.addBands(scale.rename('trend'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate mean growing season trend 2019-2023\n",
    "\n",
    "trend = yearCompCol.reduce(ee.Reducer.mean())\n",
    "\n",
    "scale = trend.select('scale_mean')\n",
    "\n",
    "trend_image = trend_image.addBands(scale.rename('season'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate change in annual max ndvi over time\n",
    "\n",
    "yearwise_ndvi = years.map(annual_images)\n",
    "\n",
    "for item in yearwise_ndvi.getInfo():\n",
    "    print(\"Year:\", item['properties']['year'], \"Number of images:\", item['properties']['num'])\n",
    "\n",
    "yearCompCol = ee.ImageCollection.fromImages(yearwise_ndvi)\n",
    "\n",
    "trend = yearCompCol.select(['system:time_start_mean',\n",
    "                            'NDVI_max'\n",
    "                             ]).reduce(ee.Reducer.linearFit())\n",
    "\n",
    "scale = trend.select('scale')\n",
    "    \n",
    "trend_image = trend_image.addBands(scale.rename('temporal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate June Greenness 2019-2023\n",
    "\n",
    "end_month = 6\n",
    "\n",
    "yearwise_ndvi = years.map(annual_images)\n",
    "\n",
    "for item in yearwise_ndvi.getInfo():\n",
    "    print(\"Year:\", item['properties']['year'], \"Number of images:\", item['properties']['num'])\n",
    "\n",
    "yearCompCol = ee.ImageCollection.fromImages(yearwise_ndvi)\n",
    "\n",
    "# Get linear fit to pixelwise trend of annual max NDVI\n",
    "trend = yearCompCol.select(['system:time_start_mean',\n",
    "                                    f'{index}_{analysis}'\n",
    "                                    ]).reduce(ee.Reducer.linearFit())\n",
    "    \n",
    "scale = trend.select('scale')\n",
    "    \n",
    "trend_image = trend_image.addBands(scale.rename('june'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = trend_image.select('temporal', 'season', 'june')\n",
    "\n",
    "training = img.sample(\n",
    "    region=aoi,\n",
    "    scale=10,\n",
    "    numPixels=5000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = ee.Clusterer.wekaKMeans(4).train(training) # integer = number of clusters\n",
    "\n",
    "kmeansresult = img.cluster(kmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot RGB\n",
    "Map.addLayer(trend_image.select('B4', 'B3', 'B2'), {'min': 0.0, 'max': 0.3}, ee.Image(trend_image).date().format('yyyy-MM-dd').getInfo(), True)\n",
    "\n",
    "# plot clusters\n",
    "Map.addLayer(kmeansresult.select('cluster'),\n",
    "              {'min':0, 'max':4,\n",
    "               # 'palette': cm.palettes.viridis\n",
    "            },\n",
    " 'kmeans')\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to df\n",
    "\n",
    "sample = kmeansresult.addBands(trend_image.select('trend', 'temporal','season','june')).sample(\n",
    "    region=aoi,\n",
    "    scale=10,\n",
    "    numPixels=5000\n",
    ").getInfo()\n",
    "\n",
    "data = []\n",
    "\n",
    "for feature in sample['features']:\n",
    "    properties = feature['properties']\n",
    "    data.append([properties['trend'], properties['temporal'], properties['season'], properties['june'], properties['cluster']])\n",
    "df = pd.DataFrame(data, columns=['trend', 'temporal', 'season', 'june', 'cluster'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "scatter = ax.scatter(df['temporal'], df['season'], df['june'], c=df['cluster'], cmap='gray')\n",
    "\n",
    "# Labels\n",
    "ax.set_xlabel('temporal')\n",
    "ax.set_ylabel('season')\n",
    "ax.set_zlabel('june')\n",
    "\n",
    "# Legend\n",
    "legend1 = ax.legend(*scatter.legend_elements(), title=\"clusters\")\n",
    "ax.add_artist(legend1)\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "scatter = plt.scatter(df['june'], df['trend'], c=df['cluster'], cmap='gray', edgecolors='k')\n",
    "\n",
    "# Labels\n",
    "plt.xlabel('june')\n",
    "plt.ylabel('trend')\n",
    "\n",
    "# Legend\n",
    "legend1 = plt.legend(*scatter.legend_elements(), title=\"Clusters\")\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(kind='box', data=df, y='temporal', x='cluster', palette=\"gray\")\n",
    "plt.tight_layout()\n",
    "# plt.title('North Slope (8100362730)')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gee",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
